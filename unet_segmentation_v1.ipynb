{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Copy_of_unet_segmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanrajmit/Unet_Semantic_Segmentation/blob/master/unet_segmentation_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b64HYlAQHyAf"
      },
      "source": [
        "# UNET SEGMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objF8nR9HyAj"
      },
      "source": [
        "Arxiv Link: <a href=\"https://arxiv.org/abs/1505.04597\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtm3R4HtHyAm"
      },
      "source": [
        "<ul>\n",
        "<li>UNet is a fully convolutional network(FCN) that does image segmentation. Its goal is to predict each pixel's class.</li>\n",
        "\n",
        "<li>UNet is built upon the FCN and modified in a way that it yields better segmentation in medical imaging.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMNXbbC2HyAp"
      },
      "source": [
        "## 1.1 Architecture\n",
        "\n",
        "<img src=\"https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/images/u-net-architecture.png?raw=1\"/>\n",
        "\n",
        "<h3>UNet Architecture has 3 parts:</h3>\n",
        "<ol>\n",
        "    <li>The Contracting/Downsampling Path</li>\n",
        "    <li>Bottleneck</li>\n",
        "    <li>The Expanding/Upsampling Path</li>\n",
        "</ol>\n",
        "\n",
        "<h3>Downsampling Path: </h3>\n",
        "<ol>\n",
        "    <li>It consists of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling.</li>\n",
        "    <li>At each downsampling step we double the number of feature channels.</li>\n",
        "</ol>\n",
        "\n",
        "<h3>Upsampling Path: </h3>\n",
        "<ol>\n",
        "     <li> Every  step  in  the  expansive  path  consists  of  an  upsampling  of  the feature map followed by a 2x2 convolution (“up-convolution”), a concatenation with the correspondingly feature  map  from  the  downsampling  path,  and  two  3x3  convolutions,  each  followed by a ReLU.</li>\n",
        "</ol>\n",
        "\n",
        "<h3> Skip Connection: </h3>\n",
        "The skip connection from the downsampling path are concatenated with feature map during upsampling path. These skip connection provide local information to global information while upsampling.\n",
        "\n",
        "<h3> Final Layer: </h3>\n",
        "At the final layer a 1x1 convolution is used to map each feature vector to the desired number of classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "!pip install kaggle\n",
        "os.environ['KAGGLE_USERNAME'] = \"mohanraj4072\"\n",
        "os.environ['KAGGLE_KEY'] = \"858be2d71e5450de7cda5fb277e16dd9\"\n"
      ],
      "metadata": {
        "id": "03laSNdzstJH",
        "outputId": "28971d6b-ae06-49d7-9d54-23a74fb19e18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FikxmodpHyAs"
      },
      "source": [
        "## 1.2 Advantages\n",
        "<h3> Advantages: </h3>\n",
        "<ol>\n",
        "    <li>The UNet combines the location information from the downsampling path to finally obtain a general information combining localisation and context, which is necessary to predict a good segmentation map.</li>\n",
        "    <li>No Dense layer is used, so image sizes can be used.</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kFcL9EHyAu"
      },
      "source": [
        "## 1.3 Dataset\n",
        "Link: <a href=\"https://www.kaggle.com/c/data-science-bowl-2018\">Data Science Bowl 2018</a>\n",
        "Find the nuclei in divergent images to advance medical discovery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfUeCxStzHa1"
      },
      "source": [
        "from imutils import paths"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voOhWeulAIW7",
        "outputId": "f375d97c-5c21-4758-d58c-527edaf38cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/s0007/Unetsegmentation.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Unetsegmentation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jMWG6u_IoM",
        "outputId": "481d62be-3c96-48a9-d443-c5c15fd606a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt install zip\n",
        "!mkdir /content/dataset\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "mkdir: cannot create directory ‘/content/dataset’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKTfXvcIBqXD",
        "outputId": "866bb468-1f01-42f0-e784-cb8e551899d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip /content/Unetsegmentation/dataset.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Unetsegmentation/dataset.zip\n",
            "replace /content/dataset/26_10.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ7p4KWhDVpG"
      },
      "source": [
        "from natsort import natsorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rW5rzdSzWhR"
      },
      "source": [
        "ImagesPath=natsorted(paths.list_images(\"/content/dataset\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byEVB88IzhOu"
      },
      "source": [
        "print(ImagesPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ImagesPath))"
      ],
      "metadata": {
        "id": "noRLlvYLiEoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO1TblmLzwsh"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "imagepath = []\n",
        "maskpath = []\n",
        "imageslist =[]\n",
        "masklist =[]\n",
        "for imagePath in ImagesPath:\n",
        "   print(imagePath)\n",
        "   image = cv2.imread(imagePath,0)\n",
        "   filename = os.path.split(imagePath)[-1]\n",
        "   csv_filename = os.path.splitext(filename)[0]\n",
        "   testfilename = csv_filename[csv_filename.rfind(\"_\") + 1:]\n",
        "   print(filename)\n",
        "   print(csv_filename)\n",
        "   print(testfilename)\n",
        "   if testfilename == \"mask\":\n",
        "     masklist.append(image)\n",
        "     maskpath.append(imagePath)\n",
        "   else:\n",
        "    imageslist.append(image)\n",
        "    imagepath.append(imagePath)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_u8iTVf32qR"
      },
      "source": [
        "import numpy as np\n",
        "image_list = np.array(imageslist)\n",
        "mask_list  = np.array(masklist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_list.shape)\n",
        "print(mask_list.shape)"
      ],
      "metadata": {
        "id": "_CTE29K8jEi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vA4kUQa7QsG"
      },
      "source": [
        "for image_path,mask_path in zip(imagepath,maskpath):\n",
        "  print(image_path, mask_path)\n",
        "\n",
        "#print(imagepath[0])\n",
        "#print(maskpath[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIAbbuol4K4p"
      },
      "source": [
        "print(image_list.shape)\n",
        "print(mask_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD3yqgAKHyAv"
      },
      "source": [
        "## 1.4 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YozOdsOQdGJs"
      },
      "source": [
        "image = image_list/255.0\n",
        "mask = mask_list/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNBK8-4wHyAw"
      },
      "source": [
        "## Imports\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "## Seeding\n",
        "seed = 2019\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "tf.seed = seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3CVvXwYHyBC"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0LJXJsSHyBM"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_R95c5sh_zi"
      },
      "source": [
        "from keras.layers import Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drbuHpRYHyBj"
      },
      "source": [
        "## Different Convolutional Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bce8M7vCHyBk"
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    print(\"up blcok\")\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "\n",
        "def up_block_resize(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    print(\"up blcok resize\")\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    print(us.shape)\n",
        "   # l1 = Lambda(lambda image: tf.image.resize_images(image,(105,145)))(us)\n",
        "   # l1=tf.image.resize_images(us, 105, 145, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "   # l2 = tf.cast(l1, tf.uint8)\n",
        "    l1 = tf.image.resize(us, [105, 145])\n",
        "    print(l1.shape)\n",
        "    concat = keras.layers.Concatenate()([l1, skip])\n",
        "    print(concat.shape)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGD0NszEHyBo"
      },
      "source": [
        "## UNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxEbgJnHyBq"
      },
      "source": [
        "def UNet():\n",
        "    f = [16, 32, 64, 128, 256,512]\n",
        "    inputs = keras.layers.Input((420, 580, 1))\n",
        "\n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0])\n",
        "    print(p1.shape)\n",
        "    c2, p2 = down_block(p1, f[1])\n",
        "    print(p2.shape)\n",
        "    c3, p3 = down_block(p2, f[2])\n",
        "    print(p3.shape)\n",
        "    c4, p4 = down_block(p3, f[3])\n",
        "    print(p4.shape)\n",
        "    c5, p5  = down_block(p4, f[4])\n",
        "    print(p5.shape)\n",
        "\n",
        "    bn = bottleneck(p5, f[5])\n",
        "\n",
        "    u1 = up_block(bn, c5, f[4])\n",
        "    print(u1.shape)\n",
        "    u2 = up_block(u1, c4, f[3])\n",
        "    print(u2.shape)\n",
        "    u3 = up_block_resize(u2, c3, f[2])\n",
        "    print(u3.shape)\n",
        "    u4 = up_block(u3, c2, f[1])\n",
        "    print(u4.shape)\n",
        "    u5 = up_block(u4, c1, f[0])\n",
        "    print(u5.shape)\n",
        "\n",
        "\n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u5)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tzke_zd8HyBv"
      },
      "source": [
        "model = UNet()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jusy-GIHyB0"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vOuxC126HyB0"
      },
      "source": [
        "model.fit(image_list,mask_list,batch_size=10,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpGl_9WVyS5P"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So2mKgLFHyB-"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1PgnWpDHyB-"
      },
      "source": [
        "## Save the Weights\n",
        "model.save_weights(\"UNetW.h5\")\n",
        "\n",
        "## Dataset for prediction\n",
        "x, y = valid_gen.__getitem__(1)\n",
        "result = model.predict(x)\n",
        "\n",
        "result = result > 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCfon6MTHyCE"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46RKYuJbHyCI"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(np.reshape(y[1]*255, (image_size, image_size)), cmap=\"gray\")\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(np.reshape(result[1]*255, (image_size, image_size)), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfMi1sfbHyCO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}